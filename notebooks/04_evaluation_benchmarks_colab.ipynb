{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation Benchmarks for Indic TTS & STT Models\n",
        "\n",
        "This notebook evaluates trained TTS and STT models against target metrics.\n",
        "\n",
        "## Metrics:\n",
        "- **TTS**: MOS Score, Speaker Similarity, Real-time Factor\n",
        "- **STT**: WER (Word Error Rate), CER (Character Error Rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q jiwer evaluate resemblyzer speechmos\n",
        "!pip install -q transformers TTS torch torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "DATA_DIR = '/content/drive/MyDrive/indic_speech_data'\n",
        "TTS_MODEL_DIR = '/content/drive/MyDrive/indic_tts_models'\n",
        "STT_MODEL_DIR = '/content/drive/MyDrive/indic_stt_models'\n",
        "\n",
        "LANGUAGE = 'hi'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. STT Evaluation (WER/CER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import evaluate\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "import soundfile as sf\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load metrics\n",
        "wer_metric = evaluate.load('wer')\n",
        "cer_metric = evaluate.load('cer')\n",
        "\n",
        "def evaluate_stt_model(model_path, test_manifest, processor=None, device='cuda'):\n",
        "    \"\"\"Evaluate STT model on test set.\"\"\"\n",
        "    \n",
        "    # Load model\n",
        "    if processor is None:\n",
        "        processor = WhisperProcessor.from_pretrained(model_path)\n",
        "    model = WhisperForConditionalGeneration.from_pretrained(model_path).to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    # Load test data\n",
        "    with open(test_manifest, 'r', encoding='utf-8') as f:\n",
        "        test_samples = [json.loads(line) for line in f if line.strip()]\n",
        "    \n",
        "    predictions = []\n",
        "    references = []\n",
        "    \n",
        "    for sample in tqdm(test_samples, desc=\"Evaluating STT\"):\n",
        "        audio_path = sample['audio_filepath']\n",
        "        reference = sample['text']\n",
        "        \n",
        "        try:\n",
        "            # Load and process audio\n",
        "            audio, sr = sf.read(audio_path, dtype='float32')\n",
        "            if sr != 16000:\n",
        "                import librosa\n",
        "                audio = librosa.resample(audio, orig_sr=sr, target_sr=16000)\n",
        "            \n",
        "            # Transcribe\n",
        "            input_features = processor(\n",
        "                audio,\n",
        "                sampling_rate=16000,\n",
        "                return_tensors='pt',\n",
        "            ).input_features.to(device)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                predicted_ids = model.generate(input_features, max_length=225)\n",
        "            \n",
        "            prediction = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
        "            \n",
        "            predictions.append(prediction)\n",
        "            references.append(reference)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {audio_path}: {e}\")\n",
        "            continue\n",
        "    \n",
        "    # Calculate metrics\n",
        "    wer = wer_metric.compute(predictions=predictions, references=references)\n",
        "    cer = cer_metric.compute(predictions=predictions, references=references)\n",
        "    \n",
        "    return {\n",
        "        'wer': wer,\n",
        "        'cer': cer,\n",
        "        'num_samples': len(predictions),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run STT evaluation\n",
        "stt_model_path = f\"{STT_MODEL_DIR}/whisper_{LANGUAGE}_merged\"\n",
        "test_manifest = f\"{DATA_DIR}/manifests/stt_{LANGUAGE}_val.jsonl\"\n",
        "\n",
        "if os.path.exists(stt_model_path) and os.path.exists(test_manifest):\n",
        "    stt_results = evaluate_stt_model(stt_model_path, test_manifest)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"STT Evaluation Results\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"  WER: {stt_results['wer']:.2%}\")\n",
        "    print(f\"  CER: {stt_results['cer']:.2%}\")\n",
        "    print(f\"  Samples: {stt_results['num_samples']}\")\n",
        "    \n",
        "    # Check against targets\n",
        "    print(\"\\nTarget Comparison:\")\n",
        "    print(f\"  WER Target (Clean): < 15% | Actual: {stt_results['wer']:.1%} {'✓' if stt_results['wer'] < 0.15 else '✗'}\")\n",
        "    print(f\"  CER Target (Clean): < 10% | Actual: {stt_results['cer']:.1%} {'✓' if stt_results['cer'] < 0.10 else '✗'}\")\n",
        "else:\n",
        "    print(\"STT model or test manifest not found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. TTS Evaluation (MOS, Speaker Similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def estimate_mos_heuristic(audio, sr):\n",
        "    \"\"\"Estimate MOS using heuristics.\"\"\"\n",
        "    scores = []\n",
        "    \n",
        "    # Clipping check\n",
        "    peak = np.max(np.abs(audio))\n",
        "    if peak > 0.99:\n",
        "        scores.append(2.0)\n",
        "    elif peak > 0.95:\n",
        "        scores.append(3.0)\n",
        "    elif peak > 0.1:\n",
        "        scores.append(4.0)\n",
        "    else:\n",
        "        scores.append(3.0)\n",
        "    \n",
        "    # RMS check\n",
        "    rms = np.sqrt(np.mean(audio ** 2))\n",
        "    if rms < 0.01:\n",
        "        scores.append(2.0)\n",
        "    elif rms < 0.1:\n",
        "        scores.append(3.5)\n",
        "    else:\n",
        "        scores.append(4.0)\n",
        "    \n",
        "    # Duration check\n",
        "    duration = len(audio) / sr\n",
        "    if duration < 0.5:\n",
        "        scores.append(2.5)\n",
        "    else:\n",
        "        scores.append(4.0)\n",
        "    \n",
        "    return np.mean(scores)\n",
        "\n",
        "def evaluate_tts_model(model, config, test_texts, reference_audio, device='cuda'):\n",
        "    \"\"\"Evaluate TTS model.\"\"\"\n",
        "    results = {\n",
        "        'mos_scores': [],\n",
        "        'rtf_values': [],\n",
        "        'speaker_similarities': [],\n",
        "    }\n",
        "    \n",
        "    # Try to load resemblyzer for speaker similarity\n",
        "    try:\n",
        "        from resemblyzer import VoiceEncoder, preprocess_wav\n",
        "        voice_encoder = VoiceEncoder()\n",
        "        ref_embedding = voice_encoder.embed_utterance(preprocess_wav(reference_audio))\n",
        "        has_resemblyzer = True\n",
        "    except:\n",
        "        has_resemblyzer = False\n",
        "        print(\"Resemblyzer not available, skipping speaker similarity.\")\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    for text in tqdm(test_texts, desc=\"Evaluating TTS\"):\n",
        "        try:\n",
        "            # Synthesize\n",
        "            start_time = time.time()\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                outputs = model.synthesize(\n",
        "                    text,\n",
        "                    config,\n",
        "                    speaker_wav=reference_audio,\n",
        "                    language=LANGUAGE,\n",
        "                )\n",
        "            \n",
        "            synthesis_time = time.time() - start_time\n",
        "            audio = outputs['wav']\n",
        "            \n",
        "            # Calculate RTF\n",
        "            audio_duration = len(audio) / 22050\n",
        "            rtf = synthesis_time / audio_duration\n",
        "            results['rtf_values'].append(rtf)\n",
        "            \n",
        "            # Estimate MOS\n",
        "            mos = estimate_mos_heuristic(audio, 22050)\n",
        "            results['mos_scores'].append(mos)\n",
        "            \n",
        "            # Speaker similarity\n",
        "            if has_resemblyzer:\n",
        "                syn_embedding = voice_encoder.embed_utterance(preprocess_wav(audio))\n",
        "                similarity = np.dot(ref_embedding, syn_embedding) / (\n",
        "                    np.linalg.norm(ref_embedding) * np.linalg.norm(syn_embedding)\n",
        "                )\n",
        "                results['speaker_similarities'].append((similarity + 1) / 2)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            continue\n",
        "    \n",
        "    return {\n",
        "        'avg_mos': np.mean(results['mos_scores']) if results['mos_scores'] else 0,\n",
        "        'avg_rtf': np.mean(results['rtf_values']) if results['rtf_values'] else 0,\n",
        "        'avg_speaker_sim': np.mean(results['speaker_similarities']) if results['speaker_similarities'] else 0,\n",
        "        'num_samples': len(results['mos_scores']),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test texts for evaluation\n",
        "test_texts_by_lang = {\n",
        "    'hi': [\n",
        "        'नमस्ते, आप कैसे हैं?',\n",
        "        'आज मौसम बहुत अच्छा है।',\n",
        "        'मुझे हिंदी में बात करना पसंद है।',\n",
        "        'भारत एक महान देश है।',\n",
        "        'शिक्षा जीवन का सबसे महत्वपूर्ण हिस्सा है।',\n",
        "    ],\n",
        "    'ta': [\n",
        "        'வணக்கம், நீங்கள் எப்படி இருக்கிறீர்கள்?',\n",
        "        'இன்று வானிலை மிகவும் நன்றாக உள்ளது।',\n",
        "        'எனக்கு தமிழில் பேசுவது பிடிக்கும்।',\n",
        "    ],\n",
        "    'te': [\n",
        "        'నమస్కారం, మీరు ఎలా ఉన్నారు?',\n",
        "        'ఈరోజు వాతావరణం చాలా బాగుంది.',\n",
        "        'నాకు తెలుగులో మాట్లాడటం ఇష్టం.',\n",
        "    ],\n",
        "}\n",
        "\n",
        "test_texts = test_texts_by_lang.get(LANGUAGE, test_texts_by_lang['hi'])\n",
        "print(f\"Test texts for {LANGUAGE}: {len(test_texts)} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run TTS evaluation (if model exists)\n",
        "tts_model_path = f\"{TTS_MODEL_DIR}/xtts_{LANGUAGE}_final\"\n",
        "\n",
        "if os.path.exists(tts_model_path):\n",
        "    from TTS.tts.configs.xtts_config import XttsConfig\n",
        "    from TTS.tts.models.xtts import Xtts\n",
        "    \n",
        "    # Load model\n",
        "    config = XttsConfig()\n",
        "    config.load_json(f\"{tts_model_path}/config.json\")\n",
        "    model = Xtts.init_from_config(config)\n",
        "    model.load_checkpoint(config, checkpoint_dir=tts_model_path)\n",
        "    model = model.cuda()\n",
        "    \n",
        "    # Load reference audio from training data\n",
        "    train_manifest = f\"{DATA_DIR}/manifests/tts_{LANGUAGE}_train.jsonl\"\n",
        "    with open(train_manifest, 'r') as f:\n",
        "        sample = json.loads(f.readline())\n",
        "    ref_audio, _ = sf.read(sample['audio_filepath'], dtype='float32')\n",
        "    \n",
        "    # Evaluate\n",
        "    tts_results = evaluate_tts_model(model, config, test_texts, ref_audio)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"TTS Evaluation Results\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"  MOS Score: {tts_results['avg_mos']:.2f}\")\n",
        "    print(f\"  Real-time Factor: {tts_results['avg_rtf']:.2f}\")\n",
        "    print(f\"  Speaker Similarity: {tts_results['avg_speaker_sim']:.2f}\")\n",
        "    \n",
        "    # Check against targets\n",
        "    print(\"\\nTarget Comparison:\")\n",
        "    print(f\"  MOS Target: > 3.5 | Actual: {tts_results['avg_mos']:.2f} {'✓' if tts_results['avg_mos'] > 3.5 else '✗'}\")\n",
        "    print(f\"  RTF Target: < 0.5 | Actual: {tts_results['avg_rtf']:.2f} {'✓' if tts_results['avg_rtf'] < 0.5 else '✗'}\")\n",
        "    print(f\"  Similarity Target: > 0.85 | Actual: {tts_results['avg_speaker_sim']:.2f} {'✓' if tts_results['avg_speaker_sim'] > 0.85 else '✗'}\")\n",
        "else:\n",
        "    print(f\"TTS model not found at {tts_model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Summary Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"EVALUATION SUMMARY - Language: {LANGUAGE}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nSTT Metrics:\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"{'Metric':<20} {'Target':<15} {'Status'}\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"{'WER (Clean)':<20} {'< 15%':<15} {'Pending'}\")\n",
        "print(f\"{'WER (Noisy)':<20} {'< 25%':<15} {'Pending'}\")\n",
        "print(f\"{'CER (Clean)':<20} {'< 10%':<15} {'Pending'}\")\n",
        "print(f\"{'CER (Noisy)':<20} {'< 15%':<15} {'Pending'}\")\n",
        "\n",
        "print(\"\\nTTS Metrics:\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"{'Metric':<20} {'Target':<15} {'Status'}\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"{'MOS Score':<20} {'> 3.5':<15} {'Pending'}\")\n",
        "print(f\"{'Speaker Similarity':<20} {'> 0.85':<15} {'Pending'}\")\n",
        "print(f\"{'Real-time Factor':<20} {'< 0.5':<15} {'Pending'}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
