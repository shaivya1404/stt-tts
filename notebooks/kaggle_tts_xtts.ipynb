{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTS with XTTS v2 - Voice Cloning\n",
    "\n",
    "**What this does:**\n",
    "- Clone any voice with just 30 seconds of audio\n",
    "- Generate speech in Hindi and English\n",
    "- No training required (uses pre-trained XTTS v2)\n",
    "\n",
    "**GPU Required:** Settings ‚Üí Accelerator ‚Üí GPU P100 or T4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"‚ùå Enable GPU in Settings!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q TTS\n",
    "!pip install -q torchaudio\n",
    "print(\"‚úÖ Packages installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load XTTS v2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.api import TTS\n",
    "import torch\n",
    "\n",
    "# Load XTTS v2 (multilingual, voice cloning)\n",
    "print(\"Loading XTTS v2 model (this may take a few minutes)...\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
    "\n",
    "print(f\"‚úÖ Model loaded on {device}!\")\n",
    "print(f\"\\nSupported languages: {tts.languages}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Upload Your Reference Audio\n",
    "\n",
    "**Requirements for reference audio:**\n",
    "- Duration: 10-30 seconds (longer is better)\n",
    "- Quality: Clear, no background noise\n",
    "- Format: WAV or MP3\n",
    "- Content: Natural speech (reading a paragraph works well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your reference audio file\n",
    "# Option 1: Use Kaggle file upload (+ Add data)\n",
    "# Option 2: Upload directly:\n",
    "\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# For Kaggle, you can upload via the file browser on the left\n",
    "# Or set the path to your uploaded dataset\n",
    "\n",
    "REFERENCE_AUDIO = \"/kaggle/input/your-dataset/reference_voice.wav\"  # UPDATE THIS PATH\n",
    "\n",
    "# Or upload from local machine (works in Colab):\n",
    "# uploaded = files.upload()\n",
    "# REFERENCE_AUDIO = list(uploaded.keys())[0]\n",
    "\n",
    "if os.path.exists(REFERENCE_AUDIO):\n",
    "    print(f\"‚úÖ Reference audio found: {REFERENCE_AUDIO}\")\n",
    "else:\n",
    "    print(\"‚ùå Reference audio not found!\")\n",
    "    print(\"Please upload your reference audio file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check reference audio quality\n",
    "import torchaudio\n",
    "import IPython.display as ipd\n",
    "\n",
    "if os.path.exists(REFERENCE_AUDIO):\n",
    "    waveform, sample_rate = torchaudio.load(REFERENCE_AUDIO)\n",
    "    duration = waveform.shape[1] / sample_rate\n",
    "    \n",
    "    print(f\"Duration: {duration:.1f} seconds\")\n",
    "    print(f\"Sample rate: {sample_rate} Hz\")\n",
    "    print(f\"Channels: {waveform.shape[0]}\")\n",
    "    \n",
    "    if duration < 6:\n",
    "        print(\"‚ö†Ô∏è Warning: Audio is short. 10-30 seconds recommended.\")\n",
    "    elif duration > 30:\n",
    "        print(\"‚ö†Ô∏è Warning: Audio is long. Will use first 30 seconds.\")\n",
    "    else:\n",
    "        print(\"‚úÖ Audio length is good!\")\n",
    "    \n",
    "    # Play the audio\n",
    "    print(\"\\nüîä Playing reference audio:\")\n",
    "    ipd.display(ipd.Audio(REFERENCE_AUDIO))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate Speech (Voice Cloning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with English\n",
    "english_text = \"Hello! This is a test of the text to speech system. The voice should sound similar to the reference audio.\"\n",
    "\n",
    "print(\"Generating English speech...\")\n",
    "tts.tts_to_file(\n",
    "    text=english_text,\n",
    "    file_path=\"/kaggle/working/output_english.wav\",\n",
    "    speaker_wav=REFERENCE_AUDIO,\n",
    "    language=\"en\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Generated: output_english.wav\")\n",
    "ipd.display(ipd.Audio(\"/kaggle/working/output_english.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with Hindi\n",
    "hindi_text = \"‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§Ø‡§π ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§ü‡•Ç ‡§∏‡•ç‡§™‡•Ä‡§ö ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§ï‡§æ ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£ ‡§π‡•à‡•§ ‡§Ü‡§µ‡§æ‡§ú‡§º ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§ë‡§°‡§ø‡§Ø‡•ã ‡§ï‡•á ‡§∏‡§Æ‡§æ‡§® ‡§π‡•ã‡§®‡•Ä ‡§ö‡§æ‡§π‡§ø‡§è‡•§\"\n",
    "\n",
    "print(\"Generating Hindi speech...\")\n",
    "tts.tts_to_file(\n",
    "    text=hindi_text,\n",
    "    file_path=\"/kaggle/working/output_hindi.wav\",\n",
    "    speaker_wav=REFERENCE_AUDIO,\n",
    "    language=\"hi\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Generated: output_hindi.wav\")\n",
    "ipd.display(ipd.Audio(\"/kaggle/working/output_hindi.wav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Generate Multiple Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate multiple test samples\n",
    "test_texts = {\n",
    "    \"en\": [\n",
    "        \"Welcome to our text to speech demonstration.\",\n",
    "        \"This technology can convert any text into natural sounding speech.\",\n",
    "        \"The voice quality depends on the reference audio provided.\",\n",
    "    ],\n",
    "    \"hi\": [\n",
    "        \"‡§Ü‡§ú ‡§ï‡§æ ‡§Æ‡•å‡§∏‡§Æ ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§π‡•à‡•§\",\n",
    "        \"‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ö‡§™‡§®‡§æ ‡§®‡§æ‡§Æ ‡§î‡§∞ ‡§™‡§§‡§æ ‡§¨‡§§‡§æ‡§è‡§Ç‡•§\",\n",
    "        \"‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶, ‡§Ü‡§™‡§ï‡§æ ‡§¶‡§ø‡§® ‡§∂‡•Å‡§≠ ‡§π‡•ã‡•§\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "import os\n",
    "os.makedirs(\"/kaggle/working/samples\", exist_ok=True)\n",
    "\n",
    "for lang, texts in test_texts.items():\n",
    "    print(f\"\\n=== Generating {lang.upper()} samples ===\")\n",
    "    for i, text in enumerate(texts):\n",
    "        output_file = f\"/kaggle/working/samples/{lang}_sample_{i+1}.wav\"\n",
    "        print(f\"\\nText: {text}\")\n",
    "        \n",
    "        tts.tts_to_file(\n",
    "            text=text,\n",
    "            file_path=output_file,\n",
    "            speaker_wav=REFERENCE_AUDIO,\n",
    "            language=lang\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Saved: {output_file}\")\n",
    "        ipd.display(ipd.Audio(output_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Create TTS Function for Easy Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(text, language=\"en\", output_path=None):\n",
    "    \"\"\"\n",
    "    Convert text to speech using cloned voice.\n",
    "    \n",
    "    Args:\n",
    "        text: Text to convert to speech\n",
    "        language: 'en' for English, 'hi' for Hindi\n",
    "        output_path: Path to save audio (optional)\n",
    "    \n",
    "    Returns:\n",
    "        Path to generated audio file\n",
    "    \"\"\"\n",
    "    if output_path is None:\n",
    "        output_path = f\"/kaggle/working/speech_{hash(text) % 10000}.wav\"\n",
    "    \n",
    "    tts.tts_to_file(\n",
    "        text=text,\n",
    "        file_path=output_path,\n",
    "        speaker_wav=REFERENCE_AUDIO,\n",
    "        language=language\n",
    "    )\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# Test the function\n",
    "audio_file = speak(\"This is a quick test of our speak function.\", language=\"en\")\n",
    "ipd.display(ipd.Audio(audio_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Fine-tune XTTS (Optional - For Better Quality)\n",
    "\n",
    "If you want even better voice matching, you can fine-tune XTTS on your voice data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning requires more data (at least 2-3 minutes of audio with transcriptions)\n",
    "# Skip this if voice cloning quality is already good enough\n",
    "\n",
    "FINETUNE = False  # Set to True to enable fine-tuning\n",
    "\n",
    "if FINETUNE:\n",
    "    print(\"Fine-tuning requires:\")\n",
    "    print(\"1. Multiple audio samples (2-5 minutes total)\")\n",
    "    print(\"2. Text transcriptions for each audio\")\n",
    "    print(\"3. A manifest.jsonl file with audio paths and text\")\n",
    "    print(\"\\nFormat of manifest.jsonl:\")\n",
    "    print('{\"audio_filepath\": \"audio1.wav\", \"text\": \"Hello world\", \"language\": \"en\"}')\n",
    "else:\n",
    "    print(\"Fine-tuning skipped. Voice cloning is usually good enough!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have training data, you can fine-tune like this:\n",
    "if FINETUNE:\n",
    "    from TTS.tts.configs.xtts_config import XttsConfig\n",
    "    from TTS.tts.models.xtts import Xtts\n",
    "    \n",
    "    # This is a simplified example\n",
    "    # Full fine-tuning code is in ml-service/training/tts/train_xtts.py\n",
    "    \n",
    "    config = XttsConfig()\n",
    "    # ... configure training\n",
    "    print(\"See train_xtts.py for full fine-tuning code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Save for Later Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save reference audio and config for deployment\n",
    "import shutil\n",
    "import json\n",
    "import os\n",
    "\n",
    "OUTPUT_DIR = \"/kaggle/working/tts_model\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Copy reference audio\n",
    "shutil.copy(REFERENCE_AUDIO, f\"{OUTPUT_DIR}/reference_voice.wav\")\n",
    "\n",
    "# Save config\n",
    "config = {\n",
    "    \"model\": \"tts_models/multilingual/multi-dataset/xtts_v2\",\n",
    "    \"reference_audio\": \"reference_voice.wav\",\n",
    "    \"languages\": [\"en\", \"hi\"],\n",
    "    \"sample_rate\": 22050,\n",
    "}\n",
    "\n",
    "with open(f\"{OUTPUT_DIR}/config.json\", \"w\") as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "# Create inference script\n",
    "inference_code = '''\n",
    "from TTS.api import TTS\n",
    "import torch\n",
    "\n",
    "# Load model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
    "\n",
    "# Reference audio path\n",
    "REFERENCE = \"reference_voice.wav\"\n",
    "\n",
    "def speak(text, language=\"en\", output_path=\"output.wav\"):\n",
    "    tts.tts_to_file(\n",
    "        text=text,\n",
    "        file_path=output_path,\n",
    "        speaker_wav=REFERENCE,\n",
    "        language=language\n",
    "    )\n",
    "    return output_path\n",
    "\n",
    "# Example usage:\n",
    "# speak(\"Hello world!\", language=\"en\", output_path=\"hello.wav\")\n",
    "# speak(\"‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ!\", language=\"hi\", output_path=\"namaste.wav\")\n",
    "'''\n",
    "\n",
    "with open(f\"{OUTPUT_DIR}/inference.py\", \"w\") as f:\n",
    "    f.write(inference_code)\n",
    "\n",
    "print(f\"‚úÖ Saved to: {OUTPUT_DIR}\")\n",
    "print(\"\\nFiles:\")\n",
    "for f in os.listdir(OUTPUT_DIR):\n",
    "    print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip for download\n",
    "import shutil\n",
    "\n",
    "# Zip all samples\n",
    "shutil.make_archive(\"/kaggle/working/tts_samples\", 'zip', \"/kaggle/working/samples\")\n",
    "\n",
    "# Zip model config\n",
    "shutil.make_archive(\"/kaggle/working/tts_deployment\", 'zip', OUTPUT_DIR)\n",
    "\n",
    "print(\"‚úÖ Created:\")\n",
    "print(\"  - tts_samples.zip (generated audio samples)\")\n",
    "print(\"  - tts_deployment.zip (reference audio + inference script)\")\n",
    "print(\"\\nüì• Download from Output panel on the right!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## How to Use Later (Local/Server)\n",
    "\n",
    "```python\n",
    "from TTS.api import TTS\n",
    "import torch\n",
    "\n",
    "# Load model (first run downloads ~2GB)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
    "\n",
    "# Generate speech with your voice\n",
    "tts.tts_to_file(\n",
    "    text=\"Hello, this is my cloned voice!\",\n",
    "    file_path=\"output.wav\",\n",
    "    speaker_wav=\"reference_voice.wav\",  # Your 30-sec recording\n",
    "    language=\"en\"\n",
    ")\n",
    "```\n",
    "\n",
    "## Supported Languages\n",
    "\n",
    "XTTS v2 supports: en, es, fr, de, it, pt, pl, tr, ru, nl, cs, ar, zh-cn, ja, hu, ko, hi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
