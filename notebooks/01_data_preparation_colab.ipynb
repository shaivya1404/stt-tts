{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preparation for Indic TTS/STT Training\n",
        "\n",
        "This notebook helps you download and prepare datasets for training TTS and STT models on Indic languages.\n",
        "\n",
        "## Datasets Covered:\n",
        "- **TTS**: IndicTTS, Kathbath, OpenSLR\n",
        "- **STT**: Shrutilipi, IndicSUPERB, Common Voice\n",
        "\n",
        "## Languages Supported:\n",
        "Hindi, Tamil, Telugu, Bengali, Marathi, Gujarati, Kannada, Malayalam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q datasets huggingface_hub soundfile librosa tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive for storage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set up output directory\n",
        "import os\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/indic_speech_data'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(f'{OUTPUT_DIR}/raw', exist_ok=True)\n",
        "os.makedirs(f'{OUTPUT_DIR}/manifests', exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Download Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from huggingface_hub import snapshot_download\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Language to download\n",
        "LANGUAGE = 'hi'  # Change to: hi, ta, te, bn, mr, etc.\n",
        "\n",
        "print(f\"Downloading data for language: {LANGUAGE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download Common Voice dataset (good for both TTS and STT)\n",
        "def download_common_voice(language, max_samples=5000):\n",
        "    \"\"\"Download Common Voice dataset.\"\"\"\n",
        "    print(f\"Loading Common Voice for {language}...\")\n",
        "    \n",
        "    try:\n",
        "        dataset = load_dataset(\n",
        "            'mozilla-foundation/common_voice_16_1',\n",
        "            language,\n",
        "            split='train',\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "        \n",
        "        if max_samples:\n",
        "            dataset = dataset.select(range(min(max_samples, len(dataset))))\n",
        "        \n",
        "        # Save to disk\n",
        "        save_path = f'{OUTPUT_DIR}/raw/common_voice_{language}'\n",
        "        dataset.save_to_disk(save_path)\n",
        "        print(f\"Saved {len(dataset)} samples to {save_path}\")\n",
        "        \n",
        "        return dataset\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading Common Voice: {e}\")\n",
        "        return None\n",
        "\n",
        "cv_dataset = download_common_voice(LANGUAGE, max_samples=5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download OpenSLR Hindi dataset\n",
        "def download_openslr_hindi():\n",
        "    \"\"\"Download OpenSLR Hindi TTS dataset.\"\"\"\n",
        "    import urllib.request\n",
        "    import zipfile\n",
        "    \n",
        "    url = \"https://www.openslr.org/resources/103/hi_in_female.zip\"\n",
        "    zip_path = f\"{OUTPUT_DIR}/raw/hi_in_female.zip\"\n",
        "    extract_path = f\"{OUTPUT_DIR}/raw/openslr_hindi\"\n",
        "    \n",
        "    print(\"Downloading OpenSLR Hindi...\")\n",
        "    urllib.request.urlretrieve(url, zip_path)\n",
        "    \n",
        "    print(\"Extracting...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    \n",
        "    print(f\"Extracted to {extract_path}\")\n",
        "    return extract_path\n",
        "\n",
        "if LANGUAGE == 'hi':\n",
        "    openslr_path = download_openslr_hindi()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Generate Training Manifests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import soundfile as sf\n",
        "import os\n",
        "\n",
        "def get_audio_duration(audio_path):\n",
        "    \"\"\"Get duration of audio file.\"\"\"\n",
        "    try:\n",
        "        info = sf.info(audio_path)\n",
        "        return info.duration\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "def create_manifest_from_hf_dataset(dataset, output_path, lang_code, dataset_type='stt'):\n",
        "    \"\"\"Create JSONL manifest from HuggingFace dataset.\"\"\"\n",
        "    entries = []\n",
        "    \n",
        "    for idx, sample in enumerate(tqdm(dataset, desc=\"Processing samples\")):\n",
        "        # Get audio path\n",
        "        audio = sample.get('audio', {})\n",
        "        audio_path = audio.get('path', '')\n",
        "        \n",
        "        # Get text\n",
        "        text = sample.get('sentence', '') or sample.get('text', '')\n",
        "        \n",
        "        if not audio_path or not text:\n",
        "            continue\n",
        "        \n",
        "        # Get duration\n",
        "        if 'array' in audio:\n",
        "            sr = audio.get('sampling_rate', 16000)\n",
        "            duration = len(audio['array']) / sr\n",
        "        else:\n",
        "            duration = sample.get('duration', 0.0)\n",
        "        \n",
        "        # Filter by duration\n",
        "        if duration < 0.5 or duration > 30.0:\n",
        "            continue\n",
        "        \n",
        "        entry = {\n",
        "            'audio_filepath': audio_path,\n",
        "            'text': text,\n",
        "            'duration': duration,\n",
        "            'language': f'{lang_code}-IN',\n",
        "            'speaker_id': sample.get('client_id', f'speaker_{idx // 100}')\n",
        "        }\n",
        "        entries.append(entry)\n",
        "    \n",
        "    # Split train/val\n",
        "    split_idx = int(len(entries) * 0.9)\n",
        "    train_entries = entries[:split_idx]\n",
        "    val_entries = entries[split_idx:]\n",
        "    \n",
        "    # Write manifests\n",
        "    train_path = f\"{output_path}/{dataset_type}_{lang_code}_train.jsonl\"\n",
        "    val_path = f\"{output_path}/{dataset_type}_{lang_code}_val.jsonl\"\n",
        "    \n",
        "    with open(train_path, 'w', encoding='utf-8') as f:\n",
        "        for entry in train_entries:\n",
        "            f.write(json.dumps(entry, ensure_ascii=False) + '\\n')\n",
        "    \n",
        "    with open(val_path, 'w', encoding='utf-8') as f:\n",
        "        for entry in val_entries:\n",
        "            f.write(json.dumps(entry, ensure_ascii=False) + '\\n')\n",
        "    \n",
        "    print(f\"Created manifests:\")\n",
        "    print(f\"  Train: {train_path} ({len(train_entries)} samples)\")\n",
        "    print(f\"  Val: {val_path} ({len(val_entries)} samples)\")\n",
        "    \n",
        "    return train_path, val_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create manifests from Common Voice\n",
        "if cv_dataset:\n",
        "    train_manifest, val_manifest = create_manifest_from_hf_dataset(\n",
        "        cv_dataset,\n",
        "        f\"{OUTPUT_DIR}/manifests\",\n",
        "        LANGUAGE,\n",
        "        dataset_type='stt'\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Audio Quality Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def validate_audio_quality(manifest_path, output_path):\n",
        "    \"\"\"Validate audio quality and filter bad samples.\"\"\"\n",
        "    valid_entries = []\n",
        "    invalid_count = 0\n",
        "    \n",
        "    with open(manifest_path, 'r', encoding='utf-8') as f:\n",
        "        entries = [json.loads(line) for line in f if line.strip()]\n",
        "    \n",
        "    for entry in tqdm(entries, desc=\"Validating audio\"):\n",
        "        audio_path = entry['audio_filepath']\n",
        "        \n",
        "        if not os.path.exists(audio_path):\n",
        "            invalid_count += 1\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            audio, sr = sf.read(audio_path, dtype='float32')\n",
        "            \n",
        "            # Check for issues\n",
        "            if audio.ndim > 1:\n",
        "                audio = np.mean(audio, axis=1)\n",
        "            \n",
        "            # Check duration\n",
        "            duration = len(audio) / sr\n",
        "            if duration < 0.5 or duration > 30.0:\n",
        "                invalid_count += 1\n",
        "                continue\n",
        "            \n",
        "            # Check for silence\n",
        "            rms = np.sqrt(np.mean(audio ** 2))\n",
        "            if rms < 0.001:\n",
        "                invalid_count += 1\n",
        "                continue\n",
        "            \n",
        "            # Check for clipping\n",
        "            if np.max(np.abs(audio)) > 0.99:\n",
        "                # Still keep but flag\n",
        "                entry['has_clipping'] = True\n",
        "            \n",
        "            entry['duration'] = duration\n",
        "            valid_entries.append(entry)\n",
        "            \n",
        "        except Exception as e:\n",
        "            invalid_count += 1\n",
        "            continue\n",
        "    \n",
        "    # Write validated manifest\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        for entry in valid_entries:\n",
        "            f.write(json.dumps(entry, ensure_ascii=False) + '\\n')\n",
        "    \n",
        "    print(f\"Validated: {len(valid_entries)} valid, {invalid_count} invalid\")\n",
        "    return output_path\n",
        "\n",
        "# Validate the training manifest\n",
        "# validated_manifest = validate_audio_quality(train_manifest, f\"{OUTPUT_DIR}/manifests/stt_{LANGUAGE}_train_validated.jsonl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Summary Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_manifest_stats(manifest_path):\n",
        "    \"\"\"Print statistics for a manifest.\"\"\"\n",
        "    with open(manifest_path, 'r', encoding='utf-8') as f:\n",
        "        entries = [json.loads(line) for line in f if line.strip()]\n",
        "    \n",
        "    durations = [e['duration'] for e in entries]\n",
        "    \n",
        "    print(f\"\\nManifest: {manifest_path}\")\n",
        "    print(f\"  Total samples: {len(entries)}\")\n",
        "    print(f\"  Total duration: {sum(durations)/3600:.2f} hours\")\n",
        "    print(f\"  Avg duration: {np.mean(durations):.2f}s\")\n",
        "    print(f\"  Min duration: {min(durations):.2f}s\")\n",
        "    print(f\"  Max duration: {max(durations):.2f}s\")\n",
        "    \n",
        "    # Language distribution\n",
        "    langs = [e.get('language', 'unknown') for e in entries]\n",
        "    from collections import Counter\n",
        "    lang_counts = Counter(langs)\n",
        "    print(f\"  Languages: {dict(lang_counts)}\")\n",
        "\n",
        "# Print stats\n",
        "# print_manifest_stats(train_manifest)\n",
        "# print_manifest_stats(val_manifest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Next Steps\n",
        "\n",
        "After running this notebook, you should have:\n",
        "1. Downloaded datasets in `{OUTPUT_DIR}/raw/`\n",
        "2. Generated manifests in `{OUTPUT_DIR}/manifests/`\n",
        "\n",
        "Next notebooks:\n",
        "- `02_tts_xtts_finetuning_colab.ipynb` - Fine-tune XTTS for TTS\n",
        "- `03_stt_whisper_finetuning_colab.ipynb` - Fine-tune Whisper for STT"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
